{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os # To find the training Files in the path\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for Detecting Face using Frontal face Haadcascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def front_face_Detection(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # this converts the Color image to Gray image for better classifying\n",
    "    face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    # face cascade object is formed to find corrdinates of faces\n",
    "    face_coordinates = face_cascade.detectMultiScale(gray_image, scaleFactor = 1.05, minNeighbors = 5)\n",
    "    # detecting the face corrdinates by giving the attribute (images, scale factor by what percentage should the image decrease everytime, minimum neighbors for classification)\n",
    "    return face_coordinates, gray_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for giving unique id to each training images and  accesing it from System Directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_images(directory):\n",
    "    face_coordinates = []\n",
    "    # creating list to store face_coordinates for each training face \n",
    "    face_id = []\n",
    "    # creating a list to store face id for eachtraining images\n",
    "    for (root, subdirectory, files) in os.walk(directory): \n",
    "    # the os walks through root, sub-directory, and each files in the system \n",
    "        for each_file in files: \n",
    "        #for each file in the files\n",
    "            if each_file.startswith(\".\"):\n",
    "            # if some external file startswith .extension eliminate that file\n",
    "                print(\"Image can't be read, skipping the file\")\n",
    "                continue\n",
    "            unique_id = os.path.basename(root)\n",
    "            # in the directory each image subdirectory should be saved as integer names, because it takes only integer input\n",
    "            #each unique_id for each_image\n",
    "            image_path = os.path.join(root, each_file)\n",
    "            # the path for each image\n",
    "            train_image = cv2.imread(image_path)\n",
    "            coordinates, gray_image = front_face_Detection(train_image)\n",
    "            if len(coordinates) != 1 :\n",
    "            # if images contain more than 1 image eliminate that image\n",
    "                #print(\"Image cant be read as for training only 1 image is required\"), #for debugging\n",
    "               # print(\"Id = \", unique_id), #for debugging\n",
    "                continue\n",
    "            x, y, w, h = coordinates[0]\n",
    "            #getting coordinates of face\n",
    "            test_image = gray_image[y:y+h, x:x+w]\n",
    "            # taking only the image of the cropped faces  \n",
    "            face_coordinates.append(test_image) # storing the values in list of image in face Coordinates\n",
    "            face_id.append(int(unique_id)) # storing only the integer values of face id \n",
    "    return face_coordinates, face_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for training each image using LBPH Face Recognizer Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_images( face_coordinates, face_id):\n",
    "    face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    # creating a LBPH Face_Recognizer Object\n",
    "    face_recognizer.train(face_coordinates, np.array(face_id))\n",
    "    #it trains the image and takes attributes as face_coordinates and n-dimensional array  face_id\n",
    "    return face_recognizer\n",
    "#Local Binary Pattern Histogram (LBPH) , generally it takes 50k images to give a perfect result\n",
    "#we are using here around 30 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawing rectangle over the face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(image, face_coordinates):\n",
    "    x, y, w, h = face_coordinates\n",
    "    # x, y - coordinates and w,h are the width and height of the images\n",
    "    cv2.rectangle(image, (x,y), (x + w, y + h), (0, 0, 255), 2)\n",
    "    # (the attributes too draw rectangle are (image, (the starting coordinates), (diagonally opposite coordinates), (color of border), width of border))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function To write predicted name on the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_text(image, text_name, x, y):\n",
    "    cv2.putText(image, text_name, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7,  (152, 251, 152), 1)\n",
    "    # attributes to write text are (image, text_name, (coordinates where to be written), FOnt style, scale of letter, color of letter, width of letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have made every Function now, we have to feed  training data to the code and predict the test images  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_coordinates, face_id = labels_to_images(\"D:\\study\\OpenCV\\Train_images_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_trained = training_images(face_coordinates, face_id)\n",
    "face_trained.save(\"Trained_images.yml\")\n",
    "#this is to save the trained images, so that we dont need to run files again and again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_image = cv2.imread(\"test1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detected, gray_image = front_face_Detection(testing_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names = { 0:\"Bill_Gates\", 1:\"Elon_Musk\", 2:\"Mark_Zuckerberg\", 3:\"Warren_Buffet\", 4:\"Zeff_Bezos\", 5:\"Ishan\"}\n",
    "#assigning the names to the concurrent _id of the person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in face_detected:\n",
    "    x, y, w, h = face\n",
    "    # assigning the coordinates of faces to the variables\n",
    "    cropped_face_image = gray_image[y:y+h, x:x+w]\n",
    "    #predicting only the cropped face\n",
    "    label, confidence = face_trained.predict(cropped_face_image)\n",
    "    #label is the image_id for concurrent person face\n",
    "    #confidence value shows something of accuracy, if confidence value is less than or equal to 37 than it shows perfect match.\n",
    "    predicted_name = Names[label]\n",
    "    #predicted the name for consequent image\n",
    "    draw_rectangle(testing_image, face)\n",
    "    #drawing rectangle to thepredicted face\n",
    "    write_text(testing_image, predicted_name, x, y)\n",
    "    #writing the concurrent names to the concurrent face\n",
    "cv2.imshow(\"Image\", testing_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recognizing Face using WebCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(1)\n",
    "webcam.set(3, 700)\n",
    "webcam.set(4, 300)\n",
    "while True:\n",
    "    check, frame = webcam.read()\n",
    "    #cv2.imshow(\"Video\", frame)\n",
    "    face_detected, gray_face = front_face_Detection(frame)\n",
    "    for face in face_detected:\n",
    "        x, y, w, h = face\n",
    "        cropped_face_image = gray_face[y:y+h, x:x+w]\n",
    "        label, confidence = face_trained.predict(cropped_face_image)\n",
    "        predicted_name = Names[label]\n",
    "        draw_rectangle(frame, face)\n",
    "        write_text(frame, predicted_name, x, y)\n",
    "    \n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('a'):\n",
    "        break\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
